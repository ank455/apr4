{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ebbfa-cd2c-4bc8-936f-e550be60fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 1\n",
    "The decision tree classifier is a popular algorithm used for both classification and regression tasks. It constructs a flowchart-like tree structure, where each internal node represents a feature or attribute, each branch represents a decision based on that attribute, and each leaf node represents the final predicted class or value.\n",
    "\n",
    "decision tree classifier algorithm works:\n",
    "(1) Data prepration\n",
    "(2) Tree Construction\n",
    "(3) Feature Selection\n",
    "(4) Splitting\n",
    "(5) Stopping Criteria \n",
    "(6) Leaf Node Assingment\n",
    "(7) Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fd09e9-bc56-481b-8034-a17d0e975fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 2\n",
    "Entropy\n",
    "Information Gain\n",
    "Splitting Criteria\n",
    "Recursive criteria\n",
    "leaf node assingmnet\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728be6bc-a80e-451f-8308-d801eb9ff7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 3\n",
    "Decision tree classifier can be used to solve a binary classification problem:\n",
    "Data prepration\n",
    "building the decision tree\n",
    "training the decision tree \n",
    "splitting and leaf node assingment \n",
    "decision path and prediction\n",
    "evaluating the decision tree \n",
    "fine tuning and improvement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c476f159-2b8c-4f67-9506-c40cc25dc828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 4\n",
    "The geometric intuition behind decision tree classification is based on dividing the feature space into regions or partitions using hyperplanes or axis-aligned splits. Each region corresponds to a leaf node in the decision tree.\n",
    "\n",
    "Feature Space\n",
    "Partitioning\n",
    "Decision Boundaries\n",
    "Regions and Leaf Nodes\n",
    "Prediction\n",
    "Decision Tree Depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7dc193-cf22-471d-9285-79cd4c6f76ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 5\n",
    "The confusion matrix is a table that summarizes the performance of a classification model by showing the counts of true positive (TP), true negative (TN), false positive (FP), and false negative (FN) predictions. It provides a comprehensive view of the model's predictions and their agreement with the actual class labels in the dataset.\n",
    "\n",
    " different components of the confusion matrix are defined:\n",
    "        \n",
    "True Positive\n",
    "True Negative\n",
    "False Positive \n",
    "False Negative\n",
    "\n",
    "The confusion matrix provides several performance metrics that can be calculated using the values in the matrix:\n",
    "Accuracy\n",
    "Precision\n",
    "recall\n",
    "Specificity\n",
    "F1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b214f8c8-e3cb-48d8-8455-a493f41190ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 6\n",
    "we have a binary classification problem where the positive class is labeled as 1 and the negative class as 0. \n",
    "Heres an example confusion matrix:\n",
    "\n",
    "               Predicted: 0    Predicted: 1  \n",
    "\n",
    "Actual: 0          92              8       \n",
    "\n",
    "Actual: 1          12              88       \n",
    "From this confusion matrix, we can calculate precision, recall, and F1 score as follows:\n",
    "\n",
    "Precision: Precision measures the proportion of correctly predicted positive instances out of all instances predicted as positive. In our example, the true positive (TP) is 88, and the false positive (FP) is 8. Therefore, precision can be calculated as:\n",
    "\n",
    "Precision = TP / (TP + FP) = 88 / (88 + 8) = 0.916\n",
    "\n",
    "So, the precision of the model is 0.916 or 91.6%.\n",
    "\n",
    "Recall: Recall (also known as sensitivity or true positive rate) measures the proportion of correctly predicted positive instances out of all actual positive instances. In our example, the true positive (TP) is 88, and the false negative (FN) is 12. Therefore, recall can be calculated as:\n",
    "\n",
    "Recall = TP / (TP + FN) = 88 / (88 + 12) = 0.88\n",
    "\n",
    "So, the recall of the model is 0.88 or 88%.\n",
    "\n",
    "F1 Score: The F1 score is the harmonic mean of precision and recall, providing a balanced measure of the model's performance. It is calculated as:\n",
    "\n",
    "F1 Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\n",
    "F1 Score = 2 * (0.916 * 0.88) / (0.916 + 0.88) = 0.897\n",
    "\n",
    "So, the F1 score of the model is 0.897 or 89.7%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a3844f-e169-4e5f-9ae5-a10a43780773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 7\n",
    "Choosing an appropriate evaluation metric is crucial in a classification problem as it directly impacts the understanding of the models performance and its suitability for the specific problem at hand. Different evaluation metrics highlight different aspects of the models performance, and the choice depends on the specific requirements and priorities of the problem.\n",
    "\n",
    "Here are a few key considerations for selecting an appropriate evaluation metric for a classification problem:\n",
    "\n",
    "Nature of the Problem\n",
    "Class Imbalance\n",
    "Costs and Consequences\n",
    "Business or Domain-Specific Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaba6c9-6c83-40ad-ab12-f9102d55b52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 8\n",
    "\n",
    "Lets consider a classification problem where precision is the most important metric: spam email classification.\n",
    "\n",
    "In spam email classification, the goal is to accurately identify whether an incoming email is spam or not. In this scenario, precision becomes a crucial evaluation metric due to the consequences of false positives, where a non-spam email is incorrectly classified as spam.\n",
    "\n",
    "Heres why precision is the most important metric in this case:\n",
    "False Positive\n",
    "Cost of mistakes\n",
    "User experience and trust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34073d3e-dff7-4e16-8a2b-594d8fda150a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 9\n",
    "Lets consider a classification problem where recall is the most important metric: cancer diagnosis.\n",
    "\n",
    "In cancer diagnosis, the goal is to accurately identify whether a patient has cancer or not. In this scenario, recall becomes a crucial evaluation metric due to the consequences of false negatives, where a patient with cancer is incorrectly classified as not having cancer.\n",
    "\n",
    "Heres why recall is the most important metric in this case:\n",
    "\n",
    "False Negatives\n",
    "Importance of Senstivity\n",
    "Clinical Impact"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
